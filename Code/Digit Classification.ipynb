{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c86bc756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5c55b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ab4d20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Dataset\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09d5ea63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data:  (60000, 28, 28)\n",
      "Shape of test data:  (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of training data: \",x_train.shape)\n",
    "print(\"Shape of test data: \",x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f26d9379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the Feature values\n",
    "x_train = x_train.astype(\"float32\")/255.0\n",
    "x_test = x_test.astype(\"float32\")/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "324ea500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the labels from integer to vector\n",
    "y_train = LabelBinarizer().fit_transform(y_train)\n",
    "y_test = LabelBinarizer().fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2d287c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the Deep Network \n",
    "# Model 1 \n",
    "# 1.Network 1 with activation function Sigmoid everywhere\n",
    "model_1 = Sequential()\n",
    "model_1.add(Flatten(input_shape = (28,28)))\n",
    "for i in range(10):\n",
    "    model_1.add(Dense(10)) #each layer has 10 neurons\n",
    "    model_1.add(Activation(\"sigmoid\"))\n",
    "    model_1.add(BatchNormalization())\n",
    "model_1.add(Dense(10,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fdb0ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                7850      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 10)               40        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 10)               40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 10)               40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 10)               40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 10)               40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 10)               40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 10)               40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 10)               40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 10)               40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 10)               40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,350\n",
      "Trainable params: 9,150\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "062098c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training model using ADAM optimizer\n",
    "batch_size = 64\n",
    "model_1.compile(optimizer=Adam(learning_rate=0.0001),loss=\"categorical_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c347edef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "938/938 [==============================] - 7s 4ms/step - loss: 1.5822 - accuracy: 0.5038 - val_loss: 1.1544 - val_accuracy: 0.6820\n",
      "Epoch 2/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 1.0041 - accuracy: 0.7265 - val_loss: 0.7736 - val_accuracy: 0.8282\n",
      "Epoch 3/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.7518 - accuracy: 0.8136 - val_loss: 0.5847 - val_accuracy: 0.8682\n",
      "Epoch 4/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.6093 - accuracy: 0.8464 - val_loss: 0.4780 - val_accuracy: 0.8876\n",
      "Epoch 5/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.5197 - accuracy: 0.8642 - val_loss: 0.4094 - val_accuracy: 0.8968\n",
      "Epoch 6/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.4643 - accuracy: 0.8752 - val_loss: 0.3649 - val_accuracy: 0.9022\n",
      "Epoch 7/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.4300 - accuracy: 0.8830 - val_loss: 0.3374 - val_accuracy: 0.9096\n",
      "Epoch 8/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.4023 - accuracy: 0.8881 - val_loss: 0.3159 - val_accuracy: 0.9116\n",
      "Epoch 9/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3851 - accuracy: 0.8915 - val_loss: 0.3011 - val_accuracy: 0.9137\n",
      "Epoch 10/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3668 - accuracy: 0.8966 - val_loss: 0.2891 - val_accuracy: 0.9172\n",
      "Epoch 11/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3527 - accuracy: 0.9006 - val_loss: 0.2772 - val_accuracy: 0.9201\n",
      "Epoch 12/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3421 - accuracy: 0.9022 - val_loss: 0.2695 - val_accuracy: 0.9236\n",
      "Epoch 13/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3336 - accuracy: 0.9041 - val_loss: 0.2630 - val_accuracy: 0.9259\n",
      "Epoch 14/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3235 - accuracy: 0.9064 - val_loss: 0.2571 - val_accuracy: 0.9262\n",
      "Epoch 15/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3141 - accuracy: 0.9097 - val_loss: 0.2500 - val_accuracy: 0.9276\n",
      "Epoch 16/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3110 - accuracy: 0.9102 - val_loss: 0.2427 - val_accuracy: 0.9310\n",
      "Epoch 17/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.3018 - accuracy: 0.9131 - val_loss: 0.2396 - val_accuracy: 0.9309\n",
      "Epoch 18/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2950 - accuracy: 0.9151 - val_loss: 0.2326 - val_accuracy: 0.9351\n",
      "Epoch 19/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2929 - accuracy: 0.9153 - val_loss: 0.2282 - val_accuracy: 0.9344\n",
      "Epoch 20/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2834 - accuracy: 0.9179 - val_loss: 0.2257 - val_accuracy: 0.9354\n",
      "Epoch 21/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2790 - accuracy: 0.9194 - val_loss: 0.2219 - val_accuracy: 0.9354\n",
      "Epoch 22/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2769 - accuracy: 0.9196 - val_loss: 0.2173 - val_accuracy: 0.9375\n",
      "Epoch 23/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2714 - accuracy: 0.9202 - val_loss: 0.2154 - val_accuracy: 0.9372\n",
      "Epoch 24/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2664 - accuracy: 0.9223 - val_loss: 0.2134 - val_accuracy: 0.9386\n",
      "Epoch 25/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2676 - accuracy: 0.9214 - val_loss: 0.2086 - val_accuracy: 0.9392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24c43cb7e20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(x_train,y_train, epochs=25,batch_size=batch_size,validation_data=(x_test,y_test), shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3a0acda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2086 - accuracy: 0.9392\n",
      "Test accuracy for model 1:  93.91999840736389  %\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network on the testing data to obtain our final classifications\n",
    "test_loss_model_1, test_acc_model_1 = model_1.evaluate(x_test,y_test)\n",
    "print(\"Test accuracy for model 1: \", test_acc_model_1*100,\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7f455ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2\n",
    "#2.Network 2 with activation function ReLU except output layer with activation function Sigmoid\n",
    "model_2 = Sequential()\n",
    "model_2.add(Flatten(input_shape = (28,28)))\n",
    "for i in range(10):\n",
    "    model_2.add(Dense(10))\n",
    "    model_2.add(Activation(\"relu\"))\n",
    "    model_2.add(BatchNormalization())\n",
    "model_2.add(Dense(10,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d31b3ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " activation_16 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " activation_17 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " activation_18 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " activation_19 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,350\n",
      "Trainable params: 9,150\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60f2f441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model using ADAM optimizer\n",
    "batch_size = 64\n",
    "model_2.compile(optimizer=Adam(learning_rate=0.0001),loss=\"categorical_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e55d4caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "938/938 [==============================] - 7s 5ms/step - loss: 2.3914 - accuracy: 0.1556 - val_loss: 2.1689 - val_accuracy: 0.2282\n",
      "Epoch 2/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.0575 - accuracy: 0.2873 - val_loss: 1.8814 - val_accuracy: 0.3567\n",
      "Epoch 3/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 1.7931 - accuracy: 0.3968 - val_loss: 1.5965 - val_accuracy: 0.4559\n",
      "Epoch 4/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 1.5287 - accuracy: 0.4685 - val_loss: 1.3381 - val_accuracy: 0.5188\n",
      "Epoch 5/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 1.3058 - accuracy: 0.5414 - val_loss: 1.1240 - val_accuracy: 0.6150\n",
      "Epoch 6/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 1.1391 - accuracy: 0.6044 - val_loss: 0.9713 - val_accuracy: 0.6750\n",
      "Epoch 7/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 1.0163 - accuracy: 0.6520 - val_loss: 0.8629 - val_accuracy: 0.7133\n",
      "Epoch 8/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.9243 - accuracy: 0.6859 - val_loss: 0.7768 - val_accuracy: 0.7494\n",
      "Epoch 9/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.8466 - accuracy: 0.7215 - val_loss: 0.7075 - val_accuracy: 0.7781\n",
      "Epoch 10/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.7829 - accuracy: 0.7522 - val_loss: 0.6446 - val_accuracy: 0.8113\n",
      "Epoch 11/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.7253 - accuracy: 0.7798 - val_loss: 0.5805 - val_accuracy: 0.8381\n",
      "Epoch 12/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.6794 - accuracy: 0.8000 - val_loss: 0.5350 - val_accuracy: 0.8531\n",
      "Epoch 13/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.6366 - accuracy: 0.8164 - val_loss: 0.5055 - val_accuracy: 0.8620\n",
      "Epoch 14/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.6082 - accuracy: 0.8249 - val_loss: 0.4819 - val_accuracy: 0.8687\n",
      "Epoch 15/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.5856 - accuracy: 0.8345 - val_loss: 0.4658 - val_accuracy: 0.8743\n",
      "Epoch 16/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.5702 - accuracy: 0.8379 - val_loss: 0.4530 - val_accuracy: 0.8764\n",
      "Epoch 17/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.5453 - accuracy: 0.8466 - val_loss: 0.4332 - val_accuracy: 0.8835\n",
      "Epoch 18/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.5348 - accuracy: 0.8505 - val_loss: 0.4208 - val_accuracy: 0.8855\n",
      "Epoch 19/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.5256 - accuracy: 0.8531 - val_loss: 0.4142 - val_accuracy: 0.8881\n",
      "Epoch 20/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.5050 - accuracy: 0.8608 - val_loss: 0.4079 - val_accuracy: 0.8904\n",
      "Epoch 21/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.5013 - accuracy: 0.8608 - val_loss: 0.3997 - val_accuracy: 0.8937\n",
      "Epoch 22/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.4922 - accuracy: 0.8658 - val_loss: 0.3955 - val_accuracy: 0.8956\n",
      "Epoch 23/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.4786 - accuracy: 0.8689 - val_loss: 0.3874 - val_accuracy: 0.8969\n",
      "Epoch 24/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.4705 - accuracy: 0.8709 - val_loss: 0.3841 - val_accuracy: 0.8996\n",
      "Epoch 25/25\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.4637 - accuracy: 0.8747 - val_loss: 0.3810 - val_accuracy: 0.8980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24c46d52760>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(x_train,y_train, epochs=25,batch_size=batch_size,validation_data=(x_test,y_test), shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbb0cd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3810 - accuracy: 0.8980\n",
      "Test accuracy for model 2:  89.80000019073486  %\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network on the testing data to obtain our final classifications\n",
    "test_loss_model_2, test_acc_model_2 = model_2.evaluate(x_test,y_test)\n",
    "print(\"Test accuracy for model 2: \", test_acc_model_2*100,\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b41e8921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Showing the testing input\n",
    "plt.figure()\n",
    "plt.imshow(x_test[1])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1c8a775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "[0.2966543  0.7037622  0.9980452  0.8917778  0.0046614  0.6652499\n",
      " 0.5423747  0.15814027 0.19204682 0.0630244 ]\n",
      "Predicted Digit: 2\n"
     ]
    }
   ],
   "source": [
    "# prediction on test data for model 1\n",
    "predictions_1 = model_1.predict(x_test)\n",
    "print(predictions_1[1])\n",
    "print(\"Predicted Digit:\",np.argmax(predictions_1[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff8c67ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "[0.6376174  0.21247324 0.9983707  0.81103754 0.12796004 0.31953353\n",
      " 0.8926251  0.19349602 0.27795613 0.5385275 ]\n",
      "Predicted Digit: 2\n"
     ]
    }
   ],
   "source": [
    "# prediction on test data for model 2\n",
    "predictions_2 = model_2.predict(x_test)\n",
    "print(predictions_2[1])\n",
    "print(\"Predicted Digit:\",np.argmax(predictions_2[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c36912",
   "metadata": {},
   "source": [
    "Model 1 - Network 1 with activation function Sigmoid everywhere\n",
    "\n",
    "Test Accuracy for Model 1:  93.92 %\n",
    "\n",
    "Model 2 - Network 2 with activation function ReLU (except in the output layer, where the activation function is Sigmoid)\n",
    "\n",
    "Test Accuracy for Model 2:  89.80 %\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074ba73a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
